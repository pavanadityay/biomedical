col = kmeans.re$cluster,
main = "K-means with 2 clusters")
kmeans.re$centers
kmeans.re$centers[,c("t", "logFC")]
points(kmeans.re$centers[, c("t", "logFC")],
col = 1:2, pch = 1, cex = 1)
## Visualizing clusters
y_kmeans <- kmeans.re$cluster
clusplot(dataset1[, c("t", "logFC")],
y_kmeans,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste("Cluster dataset"),
xlab = 't',
ylab = 'logFC')
library(caTools)
library(e1071)
library(caTools)
library(caret)
library(dplyr)
#Set the current file path as the working directory
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
dataset = read.csv("dataset/mergem.csv")
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
#dataset = dataset[-c(4)]
glimpse(dataset)
dataset = dataset[sample(1:nrow(dataset)),]
glimpse(dataset)
prc <- dataset[1:3]
prc
#dataset = dataset[1:3]
#dataset = data.frame(dataset[1:3])
#glimpse(dataset)
# Encoding the target feature as factor
#dataset$status = factor(dataset$status)
#dataset$t = as.numeric(as.factor(dataset$t))
#dataset$logFC = as.numeric(as.factor(dataset$logFC))
#dataset$status = as.numeric(as.factor(dataset$status))
#dataset$status
#dataset$P.Value = as.numeric(as.factor(dataset$P.value))
#glimpse(dataset$status)
# Splitting the dataset into the Training set and Test set
#install.packages('caTools')
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
prc_n <- as.data.frame(lapply(prc[1:2], normalize))
#training_set <- as.data.frame(lapply(training_set[1:2], normalize))
#dataset <- as.data.frame(lapply(dataset[1:2], normalize))
#print(dataset)
prc_train <- prc_n[1:350,]
#prc_train
prc_test <- prc_n[351:500,]
prc_train_labels <- prc[1:350, 3]
prc_test_labels <- prc[351:500, 3]
library(class)
library(gmodels)
prc_test_pred <- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=8)
# k = 8 gives the best accuracy
#install.packages("gmodels")
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq = FALSE)
tab <- table(prc_test_pred,prc_test_labels)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
dataset = read.csv("dataset/mergem.csv")
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
#dataset = dataset[-c(4)]
glimpse(dataset)
dataset = dataset[sample(1:nrow(dataset)),]
glimpse(dataset)
prc <- dataset[1:3]
prc
#dataset = dataset[1:3]
#dataset = data.frame(dataset[1:3])
#glimpse(dataset)
# Encoding the target feature as factor
#dataset$status = factor(dataset$status)
#dataset$t = as.numeric(as.factor(dataset$t))
#dataset$logFC = as.numeric(as.factor(dataset$logFC))
#dataset$status = as.numeric(as.factor(dataset$status))
#dataset$status
#dataset$P.Value = as.numeric(as.factor(dataset$P.value))
#glimpse(dataset$status)
# Splitting the dataset into the Training set and Test set
#install.packages('caTools')
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
prc_n <- as.data.frame(lapply(prc[1:2], normalize))
#training_set <- as.data.frame(lapply(training_set[1:2], normalize))
#dataset <- as.data.frame(lapply(dataset[1:2], normalize))
#print(dataset)
prc_train <- prc_n[1:350,]
#prc_train
prc_test <- prc_n[351:500,]
prc_train_labels <- prc[1:350, 3]
prc_test_labels <- prc[351:500, 3]
library(class)
library(gmodels)
prc_test_pred <- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=8)
# k = 8 gives the best accuracy
#install.packages("gmodels")
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq = FALSE)
tab <- table(prc_test_pred,prc_test_labels)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
library(dplyr)
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
dataset = read.csv("dataset/mergem.csv")
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
glimpse(dataset)
dataset = dataset[sample(1:nrow(dataset)),]
#dataset = dataset[1:3]
dataset = data.frame(dataset[1:3])
glimpse(dataset)
# Encoding the target feature as factor
#dataset$status = factor(dataset$status)
dataset$t = as.numeric(as.factor(dataset$t))
dataset$logFC = as.numeric(as.factor(dataset$logFC))
dataset$status = as.numeric(as.factor(dataset$status))
dataset$status
#dataset$P.Value = as.numeric(as.factor(dataset$P.value))
#glimpse(dataset$status)
# Splitting the dataset into the Training set and Test set
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
glimpse(training_set)
#glimpse(test_set)
# Feature Scaling
#training_set = scale(training_set[,1:2])
training_set
#test_set = scale(test_set[,1:2])
#test_set = data.frame(test_set)
#training_set = data.frame(training_set)
head(test_set)
library(e1071)
library(caTools)
library(caret)
set.seed(120)  # Setting Seed
classifier_cl <- naiveBayes(status ~ t+logFC, data = training_set)
classifier_cl
#install.packages("magrittr") # package installations are only needed the first time you use it
#install.packages("dplyr")    # alternative installation of the %>%
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
pre <- predict(classifier_cl, test_set, type = "class")
# Confusion Matrix
cm <- table(test_set$status, pre)
cm
accuracy_test_bayes <- sum(diag(cm)) / sum(cm)
list('predict matrix' = cm, 'accuracy' = accuracy_test_bayes)
# Model Evaluation
confusionMatrix(cm)
require("neuralnet")
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
#load the dataset
dataset = read.csv("dataset/mergem.csv")
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
dataset = dataset[-c(4)]
dataset = dataset[sample(1:nrow(dataset)),]
glimpse(dataset)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
df <- as.data.frame(lapply(dataset[1:3], normalize))
df
nn=neuralnet(status~ .,data=df, hidden=5,act.fct = "logistic",
linear.output = FALSE)
#plot(nn)
train_test_split_index <- 0.8 * nrow(df)
train <- df[1:train_test_split_index,]
head(train)
test <- df[(train_test_split_index+1): nrow(df),]
head(test)
X_train <- scale(train[, c(0:1)])
y_train <- train$status
dim(y_train) <- c(length(y_train), 1) # add extra dimension to vector
X_test <- scale(test[, c(0:1)])
y_test <- test$status
dim(y_test) <- c(length(y_test), 1) # add extra dimension to vector
X_train <- as.matrix(X_train, byrow=TRUE)
X_train <- t(X_train)
y_train <- as.matrix(y_train, byrow=TRUE)
y_train <- t(y_train)
X_test <- as.matrix(X_test, byrow=TRUE)
X_test <- t(X_test)
y_test <- as.matrix(y_test, byrow=TRUE)
y_test <- t(y_test)
getLayerSize <- function(X, y, hidden_neurons, train=TRUE) {
n_x <- dim(X)[1]
n_h <- hidden_neurons
n_y <- dim(y)[1]
size <- list("n_x" = n_x,
"n_h" = n_h,
"n_y" = n_y)
return(size)
}
layer_size <- getLayerSize(X_train, y_train, hidden_neurons = 5)
layer_size
length(y_test)
Predict=compute(nn,y_test)
Predict$net.result
prob <- Predict$net.result
pred <- ifelse(prob>0.5, 1, 0)
pred
Predict=compute(nn,test)
Predict$net.result
library(dplyr)
predict
length(prob)
length(test[3])
test[3]
glimpse(prob)
#test <- as.numeric(as.factor(test[1:2]))
tab <- table(prob,test[3])
tab
require("neuralnet")
#install.packages("tidyverse")
library(tidyverse)
library(neuralnet)
library(GGally)
library(dplyr)
#load the dataset
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
dataset = read.csv("dataset/mergem.csv")
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
dataset = dataset[-c(4)]
dataset = dataset[sample(1:nrow(dataset)),]
glimpse(dataset)
Hab_Data <- dataset
scale01 <- function(x){
(x - min(x)) / (max(x) - min(x))
}
Hab_Data <- Hab_Data %>%
mutate(t = scale01(t),
logFC = scale01(logFC),
status = as.numeric(status)-1)
Hab_Data <- Hab_Data %>%
mutate(status = as.integer(status) - 1,
status = ifelse(status == 1, TRUE, FALSE))
#df <- as.data.frame(lapply(dataset[1:3], normalize))
ggpairs(Hab_Data, title = "Scatterplot Matrix of the Features of the Data Set")
set.seed(123)
Hab_NN1 <- neuralnet(status ~ t + logFC,
data = Hab_Data,
linear.output = FALSE,
err.fct = 'ce',
likelihood = TRUE)
plot(Hab_NN1, rep = 'best')
set.seed(123)
# 2-Hidden Layers, Layer-1 2-neurons, Layer-2, 1-neuron
Hab_NN2 <- neuralnet(status ~ t + logFC,
data = Hab_Data,
linear.output = FALSE,
err.fct = 'ce',
likelihood =
TRUE, hidden = c(2,1))
# 2-Hidden Layers, Layer-1 2-neurons, Layer-2, 2-neurons
set.seed(123)
Hab_NN3 <- Hab_NN2 <- neuralnet(status ~ t + logFC,
data = Hab_Data,
linear.output = FALSE,
err.fct = 'ce',
likelihood = TRUE,
hidden = c(2,2))
# 2-Hidden Layers, Layer-1 1-neuron, Layer-2, 2-neuron
set.seed(123)
Hab_NN4 <- Hab_NN2 <- neuralnet(status ~ t + logFC,
data = Hab_Data,
linear.output = FALSE,
err.fct = 'ce',
likelihood = TRUE,
hidden = c(1,2))
# Bar plot of results
Class_NN_ICs <- tibble('Network' = rep(c("NN1", "NN2", "NN3", "NN4"), each = 3),
'Metric' = rep(c('AIC', 'BIC', 'ce Error * 100'), length.out = 12),
'Value' = c(Hab_NN1$result.matrix[4,1], Hab_NN1$result.matrix[5,1],
100*Hab_NN1$result.matrix[1,1], Hab_NN2$result.matrix[4,1],
Hab_NN2$result.matrix[5,1], 100*Hab_NN2$result.matrix[1,1],
Hab_NN3$result.matrix[4,1], Hab_NN3$result.matrix[5,1],
100*Hab_NN3$result.matrix[1,1], Hab_NN4$result.matrix[4,1],
Hab_NN4$result.matrix[5,1], 100*Hab_NN4$result.matrix[1,1]))
Class_NN_ICs %>%
ggplot(aes(Network, Value, fill = Metric)) +
geom_col(position = 'dodge')  +
ggtitle("AIC, BIC, and Cross-Entropy Error of the Classification ANNs", "Note: ce Error displayed is 100 times its true value")
# Load the library
library(GEOquery)
library(limma)
library(umap)
library(dplyr)
library(randomForest)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(e1071)
library(caTools)
library(caret)
library(GEOquery)
library(limma)
library(umap)
library(dplyr)
library(randomForest)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(e1071)
library(caTools)
library(caret)
#load the dataset
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
dataset = read.csv("dataset/mergem.csv")
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
dataset = dataset[-c(4)]
dataset = dataset[sample(1:nrow(dataset)),]
glimpse(dataset)
#normalize <- function(x) {
# return ((x - min(x)) / (max(x) - min(x))) }
#prc_n <- as.data.frame(lapply(dataset[1:3], normalize))
#dataset = prc_n
dataset$t = as.numeric(as.factor(dataset$t))
dataset$logFC = as.numeric(as.factor(dataset$logFC))
dataset$status = as.numeric(as.factor(dataset$status))
dataset$status
# Create random forest
set.seed(123)
split = sample.split(dataset, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
test_set
# For classification
rf <- randomForest(status ~ t+logFC,
data = training_set,
importance = TRUE,
proximity = TRUE)
print(rf)
pred = predict(rf, newdata=test_set[-3])
#round(pred)
length(pred)
length(test_set)
test_set
h = table(round(pred),test_set$status)
h
accuracy_test_bayes <- sum(diag(h)) / sum(h)
list('predict matrix' = h, 'accuracy' = accuracy_test_bayes)
# Model Evaluation
confusionMatrix(h)
# Output to be present
# As PNG file
png(file = "output/randomForestClassification1.png")
# Plot the error vs
# The number of trees graph
plot(rf)
# Saving the file
dev.off()
library(dplyr)
library(randomForest)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(e1071)
library(caTools)
library(caret)
library(ElemStatLearn)
#load the dataset
install.packages(ElemStatLearn)
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
dataset = dataset[-c(4)]
dataset = dataset[sample(1:nrow(dataset)),]
glimpse(dataset)
dataset$status = factor(dataset$status)
set.seed(123)
split = sample.split(dataset$status, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
glimpse(test_set)
classifier = svm(formula = status ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
#plot(y_pred, newdata = test_set[, 3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
cm
cm = table(test_set[, 3], y_pred)
cm = table(test_set[0, 3], y_pred)
cm = table(test_set[, 3], y_pred)
cm
accuracy <- sum(diag(cm)) / sum(cm)
list('predict matrix' = cm, 'accuracy' = accuracy)
confusionMatrix(cm)
# Plotting the training data set results
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
#glimpse(X1)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
#glimpse(X2)
grid_set = expand.grid(X1, X2)
#print(grid_set)
colnames(grid_set) = c('t', 'logFC')
y_grid = predict(classifier, newdata = grid_set, , type ='class')
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 't', ylab = 'logFC',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'coral1', 'aquamarine'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
this.dir <- dirname(getSourceEditorContext()$path)# frame(3) also works.
setwd(this.dir)
setwd('..')
#load the dataset
dataset = read.csv("dataset/mergem.csv")
dataset = dataset[-c(1)]
dataset = dataset[-c(3)]
dataset = dataset[-c(4)]
dataset = dataset[sample(1:nrow(dataset)),]
glimpse(dataset)
dataset$status = factor(dataset$status)
set.seed(123)
split = sample.split(dataset$status, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
g
glimpse(test_set)
classifier = svm(formula = status ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
#plot(y_pred, newdata = test_set[, 3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
cm
accuracy <- sum(diag(cm)) / sum(cm)
list('predict matrix' = cm, 'accuracy' = accuracy)
list('predict matrix' = cm, 'accuracy' = accuracy)
# Model Evaluation
confusionMatrix(cm)
list('predict matrix' = cm, 'accuracy' = accuracy)
# Model Evaluation
confusionMatrix(cm)
# Plotting the training data set results
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
#glimpse(X1)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
#glimpse(X2)
grid_set = expand.grid(X1, X2)
#print(grid_set)
colnames(grid_set) = c('t', 'logFC')
y_grid = predict(classifier, newdata = grid_set, , type ='class')
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 't', ylab = 'logFC',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'coral1', 'aquamarine'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
png(file = "output/svm.png")
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
#glimpse(X1)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
#glimpse(X2)
grid_set = expand.grid(X1, X2)
#print(grid_set)
colnames(grid_set) = c('t', 'logFC')
y_grid = predict(classifier, newdata = grid_set, , type ='class')
plot(set[, -3],
main = 'SVM (Test set)',
xlab = 't', ylab = 'logFC',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'coral1', 'aquamarine'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
precision(data = test_pred, reference = test_set$status  , positive = "0")
library(caret)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
svm_Linear <- train(status ~., data = training_set, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
